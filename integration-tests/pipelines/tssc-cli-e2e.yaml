---
apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  name: tssc-install-e2e
spec:
  description: |-
    This pipeline automates the process of running end-to-end tests for TSSC
    using a ROSA (Red Hat OpenShift Service on AWS) cluster. The pipeline provisions
    the ROSA cluster, installs TSSC using the installer, runs the tests, collects artifacts,
    and finally deprovisions the ROSA cluster.
  params:
    - name: test-name
      description: 'The name of the test corresponding to a defined Konflux integration test.'
      default: ''
      type: string
    - name: ocp-version
      description: 'The OpenShift version to use for the ephemeral cluster deployment.'
      type: string
    - name: cloud-credential-key
      type: string
      description: The key secret from konflux-test-infra-secret where all AWS ROSA configurations are stored.
    - name: replicas
      description: 'The number of replicas for the cluster nodes.'
      type: string
    - name: machine-type
      description: 'The type of machine to use for the cluster nodes.'
      type: string
    - name: job-spec
      type: string
    - name: konflux-test-infra-secret
      description: The name of secret where testing infrastructures credentials are stored.
      type: string
    - name: rhads-config
      type: string
      description: "The rhads-config file in string format."
    - name: tssc-image
      type: string
      description: "Image from where the `tssc` binary will be extracted (from path /usr/local/bin)."
      default: "quay.io/redhat-user-workloads/rhtap-shared-team-tenant/tssc-cli:latest"
    - name: tssc-test-image
      type: string
      description: "Image from where the `tssc-test` binary will be extracted (from path /usr/local/bin)."
      default: "quay.io/redhat-user-workloads/rhtap-shared-team-tenant/tssc-test:latest"
    - name: testplan
      type: string
      description: 'Optional testplan.json content encoded in base64 format. If not provided, testplan will be downloaded from the repository.'
      default: ""
  tasks:
    - name: provision-cluster
      taskSpec:
        results:
          - name: ocp-login-command
            value: "$(steps.claim-cluster.results.ocp-login-command)"
        volumes:
          - name: hive-creds-volume
            secret:
              secretName: rhopp-test
          - name: credentials
            emptyDir: {}
        steps:
          - name: claim-cluster
            image: registry.redhat.io/openshift4/ose-cli@sha256:15da03b04318bcc842060b71e9dd6d6c2595edb4e8fdd11b0c6781eeb03ca182
            volumeMounts:
              - name: hive-creds-volume
                mountPath: /usr/local/hive-creds
            results:
              - name: ocp-login-command
                description: "Ocp login command"
            script: |
              #!/usr/bin/bash
              oc login $(cat /usr/local/hive-creds/kube_api_url) -u cluster-admin -p $(cat /usr/local/hive-creds/password)
              oc whoami
              oc get clusterpool -n hive
              oc create -f - <<EOF
              apiVersion: hive.openshift.io/v1
              kind: ClusterClaim
              metadata:
                name: $(context.pipelineRun.name)
                namespace: hive
              spec:
                clusterPoolName: clusterpool
              EOF
              ## wait for cluster for up to 60 minutes
              if ! kubectl wait --for=condition=ClusterRunning clusterclaims.hive.openshift.io/$(context.pipelineRun.name) -n hive --timeout 60m; then
                echo "Cluster failed to start in 60 minutes. Deleting clusterClaim"
                oc delete clusterclaims.hive.openshift.io/$(context.pipelineRun.name) -n hive
                exit 1
              fi
              cp_namespace=$(oc get clusterclaims.hive.openshift.io -n hive $(context.pipelineRun.name) -o jsonpath={.spec.namespace})
              api_url=$(oc get clusterdeployment -n $cp_namespace  $cp_namespace -o jsonpath={.status.apiURL})
              admin_pass_secret=$(oc get clusterdeployment -n $cp_namespace  $cp_namespace -o jsonpath={.spec.clusterMetadata.adminPasswordSecretRef.name})
              kubeadminpass=$(oc get secret $admin_pass_secret -n $cp_namespace -o jsonpath={.data.password} |base64 -d)
              echo "oc login --insecure-skip-tls-verify=true $api_url -u kubeadmin -p $kubeadminpass" > $(step.results.ocp-login-command.path)

              kubeconfig_secret=$(oc get clusterdeployment -n $cp_namespace  $cp_namespace -o jsonpath={.spec.clusterMetadata.adminKubeconfigSecretRef.name})

              oc get secret -n $cp_namespace $kubeconfig_secret -o jsonpath={.data.kubeconfig} |base64 -d > /tmp/ephemereal.config
              export KUBECONFIG=/tmp/ephemereal.config
              csr_max_retries=5
              csr_sleep_duration=10
              approved_csrs=false

              console_max_retries=30
              console_sleep_duration=10
              console_connect_timeout=10
              console_accessible=false

              echo "--- Starting CSR Approval Process ---"
              for ((i=1; i<=csr_max_retries; i++)); do
                echo "CSR Attempt $i of $csr_max_retries: Checking for pending CSRs..."
                if ! oc get csr 2>/dev/null | grep -i Pending; then
                  echo "No pending CSRs found. Continuing"
                  approved_csrs=true
                  break
                else
                  echo "There are pending CSRs. That probably means cluster was hibernated for more than 24 hours. Need to approve them (until OCPBUGS-55339 is resolved)"
                  if oc get csr -oname | xargs oc adm certificate approve; then
                    echo "Successfully submitted approval for CSRs on attempt $i."
                    sleep 2 # Small delay for changes to propagate
                    if ! oc get csr 2>/dev/null | grep -i Pending; then
                      echo "Confirmed no pending CSRs after approval."
                      approved_csrs=true
                      break
                    else
                      echo "Pending CSRs still exist after approval attempt $i."
                    fi
                  else
                    echo "Failed to run approval command for CSRs on attempt $i."
                  fi
                fi

                if [[ "$i" -lt "$csr_max_retries" ]]; then
                  echo "Sleeping for $csr_sleep_duration seconds before next CSR retry..."
                  sleep "$csr_sleep_duration"
                fi
              done

              if [[ "$approved_csrs" == "true" ]]; then
                echo "CSR check and approval process completed successfully."
              else
                echo "Failed to ensure all pending CSRs were approved after $csr_max_retries attempts."
                exit 1
              fi
              echo "--- CSR Approval Process Finished ---"

              # --- Console URL Accessibility Check ---
              echo "--- Starting Console Accessibility Check ---"


              oc whoami
              console_url=$(oc whoami --show-console)
              echo "Console URL: $console_url"
              # # Check if routes are available (OpenShift-specific resource)
              # echo "Checking if routes are available..."
              # if ! oc api-resources | grep -q "routes"; then
              #   echo "Warning: Routes are not available. This might not be an OpenShift cluster or it's not fully ready."
              #   echo "Waiting for OpenShift components to be ready..."
              #   sleep 30
              #   if ! oc api-resources | grep -q "routes"; then
              #     echo "Error: Routes still not available. This doesn't appear to be an OpenShift cluster."
              #     exit 1
              #   fi
              # fi

              # # Check if openshift-console namespace exists
              # echo "Checking if openshift-console namespace exists..."
              # if ! oc get namespace openshift-console &>/dev/null; then
              #   echo "Error: openshift-console namespace not found."
              #   exit 1
              # fi

              # # Wait for console route to be available
              # echo "Waiting for console route to be available..."
              # for ((k=1; k<=10; k++)); do
              #   if oc get route console -n openshift-console &>/dev/null; then
              #     echo "Console route found."
              #     break
              #   fi
              #   echo "Console route not found, attempt $k/10. Waiting 30 seconds..."
              #   sleep 30
              # done

              # console_url="https://$(oc get route console -n openshift-console -o jsonpath='{.spec.host}' 2>/dev/null)"

              if [[ -z "$console_url" ]]; then
                echo "Error: Could not retrieve OpenShift console URL."
                exit 1
              else
                echo "Console URL found: $console_url"
                for ((j=1; j<=console_max_retries; j++)); do
                  echo "Console Check Attempt $j of $console_max_retries: Checking console URL accessibility..."
                  if curl -k --silent --output /dev/null --head --fail --connect-timeout "$console_connect_timeout" "$console_url"; then
                    echo "Console URL $console_url is accessible (HTTP 2xx)."
                    console_accessible=true
                    break
                  else
                    curl_exit_code=$?
                    echo "Console URL $console_url not accessible on attempt $j (curl exit code: $curl_exit_code)."
                  fi

                  if [[ "$j" -lt "$console_max_retries" ]]; then
                    echo "Sleeping for $console_sleep_duration seconds before next console check retry..."
                    sleep "$console_sleep_duration"
                  fi
                done

                if [[ "$console_accessible" == "true" ]]; then
                  echo "Console is ready. Continuing."
                else
                  echo "Failed to access console URL $console_url after $console_max_retries attempts."
                  exit 1
                fi
              fi
              echo "--- Console Accessibility Check Finished ---"
    - name: tssc-install
      runAfter:
        - provision-cluster
      taskRef:
        resolver: git
        params:
          - name: url
            value: https://github.com/redhat-appstudio/tssc-cli.git
          - name: revision
            value: main
          - name: pathInRepo
            value: integration-tests/tasks/tssc-install.yaml
      params:
        - name: ocp-login-command
          value: "$(tasks.provision-cluster.results.ocp-login-command)"
        - name: job-spec
          value: "$(params.job-spec)"
        - name: rhads-config
          value: $(params.rhads-config)
        - name: tssc-image
          value: $(params.tssc-image)
    - name: sprayproxy-provision
      runAfter:
        - tssc-install
      taskRef:
        resolver: git
        params:
          - name: url
            value: https://github.com/konflux-ci/tekton-integration-catalog.git
          - name: revision
            value: main
          - name: pathInRepo
            value: tasks/sprayproxy/sprayproxy-provision/0.1/sprayproxy-provision.yaml
      params:
        - name: ocp-login-command
          value: "$(tasks.provision-cluster.results.ocp-login-command)"
    - name: tssc-e2e-tests
      runAfter:
        - sprayproxy-provision
      taskRef:
        resolver: git
        params:
          - name: url
            value: https://github.com/redhat-appstudio/tssc-test.git
          - name: revision
            value: main
          - name: pathInRepo
            value: integration-tests/tasks/tssc-e2e.yaml
      params:
        - name: job-spec
          value: $(params.job-spec)
        - name: ocp-login-command
          value: "$(tasks.provision-cluster.results.ocp-login-command)"
        - name: oci-container
          value: "quay.io/konflux-test-storage/rhtap-team/rhtap-cli:$(context.pipelineRun.name)"
        - name: tssc-test-image
          value: $(params.tssc-test-image)
        - name: testplan
          value: $(params.testplan)
    - name: rhtap-ui-tests
      runAfter:
        - tssc-e2e-tests
      onError: continue
      taskRef:
        resolver: git
        params:
          - name: url
            value: https://github.com/redhat-appstudio/tssc-test.git
          - name: revision
            value: main
          - name: pathInRepo
            value: integration-tests/tasks/tssc-ui.yaml
      params:
        - name: job-spec
          value: $(params.job-spec)
        - name: ocp-login-command
          value: "$(tasks.provision-cluster.results.ocp-login-command)"
        - name: oci-container
          value: "quay.io/konflux-test-storage/rhtap-team/rhtap-cli:$(context.pipelineRun.name)"
        - name: tssc-test-image
          value: $(params.tssc-test-image)
        - name: testplan
          value: $(params.testplan)
  finally:
    - name: deprovision-cluster
      taskSpec:
        volumes:
          - name: hive-creds-volume
            secret:
              secretName: rhopp-test
          - name: credentials
            emptyDir: {}
        steps:
          - name: deprovision-cluster
            image: registry.redhat.io/openshift4/ose-cli@sha256:15da03b04318bcc842060b71e9dd6d6c2595edb4e8fdd11b0c6781eeb03ca182
            volumeMounts:
              - name: hive-creds-volume
                mountPath: /usr/local/hive-creds
            script: |
              #!/usr/bin/bash
              set -x
              oc login $(cat /usr/local/hive-creds/kube_api_url) -u cluster-admin -p $(cat /usr/local/hive-creds/password)
              oc whoami
              oc delete clusterclaims.hive.openshift.io $(context.pipelineRun.name) -n hive
    - name: sprayproxy-deprovision
      when:
        - input: "$(tasks.sprayproxy-provision.status)"
          operator: in
          values:
            - "Succeeded"
      taskRef:
        resolver: git
        params:
          - name: url
            value: https://github.com/konflux-ci/tekton-integration-catalog.git
          - name: revision
            value: main
          - name: pathInRepo
            value: tasks/sprayproxy/sprayproxy-deprovision/0.1/sprayproxy-deprovision.yaml
      params:
        - name: ocp-login-command
          value: "$(tasks.provision-cluster.results.ocp-login-command)"
    - name: pull-request-status-message
      taskRef:
        resolver: git
        params:
          - name: url
            value: https://github.com/konflux-ci/tekton-integration-catalog.git
          - name: revision
            value: main
          - name: pathInRepo
            value: tasks/pull-request-comment/0.2/pull-request-comment.yaml
      params:
        - name: test-name
          value: "$(context.pipelineRun.name)"
        - name: oci-container
          value: "quay.io/konflux-test-storage/rhtap-team/rhtap-cli:$(context.pipelineRun.name)"
        - name: pipeline-aggregate-status
          value: "$(tasks.status)"
        - name: job-spec
          value: "$(params.job-spec)"
    - name: store-pipeline-status
      taskRef:
        resolver: git
        params:
          - name: url
            value: https://github.com/konflux-ci/tekton-integration-catalog.git
          - name: revision
            value: main
          - name: pathInRepo
            value: tasks/store-pipeline-status/0.1/store-pipeline-status.yaml
      params:
        - name: oci-ref
          value: "quay.io/konflux-test-storage/rhtap-team/rhtap-cli:$(context.pipelineRun.name)"
        - name: credentials-secret-name
          value: "$(params.konflux-test-infra-secret)"
        - name: pipeline-aggregate-status
          value: $(tasks.status)
        - name: pipelinerun-name
          value: $(context.pipelineRun.name)
